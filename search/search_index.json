{
    "docs": [
        {
            "location": "/",
            "text": "ServiceX\n\n\nServiceX, a component of the IRIS-HEP DOMA group's iDDS, will be an\nexperiment-agnostic service to enable on-demand data delivery along the concepts\noriginally developed for ATLAS but specifically tailored for nearly-interactive,\nhigh performance, array based and pythonic analyses context. It will provide\nuniform backend interfaces to data storage services and  frontend\n(client-facing) service endpoints for multiple different data formats and\norganizational structures.  \n\n\nIt should be capable of retrieving and delivering\ndata from data lakes, as those systems and models evolve. It will depend on one\nor more data management systems (eg. Rucio) to find and access the data. The\nservice will be capable of on-the-fly data transformations to enable data\ndelivery in a variety of different formats, including streams of ROOT data,\nsmall ROOT files, HDF5, and Apache Arrow buffers as examples. In addition,\nServiceX will include pre-processing functionality for event data and\npreparation for multiple clustering frameworks (e.g. such as Spark).  It will be\nable to automatically unpack compressed formats, potentially including hardware\naccelerated techniques, and can prefilter events so that only useful data is\ntransmitted to the user.\n\n\n\n\nDocumentation\n\n\n\n\nService frontend\n\n\nService REST API",
            "title": "Home"
        },
        {
            "location": "/#servicex",
            "text": "ServiceX, a component of the IRIS-HEP DOMA group's iDDS, will be an\nexperiment-agnostic service to enable on-demand data delivery along the concepts\noriginally developed for ATLAS but specifically tailored for nearly-interactive,\nhigh performance, array based and pythonic analyses context. It will provide\nuniform backend interfaces to data storage services and  frontend\n(client-facing) service endpoints for multiple different data formats and\norganizational structures.    It should be capable of retrieving and delivering\ndata from data lakes, as those systems and models evolve. It will depend on one\nor more data management systems (eg. Rucio) to find and access the data. The\nservice will be capable of on-the-fly data transformations to enable data\ndelivery in a variety of different formats, including streams of ROOT data,\nsmall ROOT files, HDF5, and Apache Arrow buffers as examples. In addition,\nServiceX will include pre-processing functionality for event data and\npreparation for multiple clustering frameworks (e.g. such as Spark).  It will be\nable to automatically unpack compressed formats, potentially including hardware\naccelerated techniques, and can prefilter events so that only useful data is\ntransmitted to the user.   Documentation   Service frontend  Service REST API",
            "title": "ServiceX"
        },
        {
            "location": "/Implementation_reference/",
            "text": "Implementation reference\n\n\nAPI\n\n\nTODO: \n\n\nimediate\n\n\n\n\nlogic in request to make it DONE when events processed finished.\n\n\nlogic in request to stop transformers when events served > needed.\n\n\nmake request buttons on web site correctly behave \n\n\ndefine getters and setters for drequest and dpath variables. functions to go from es to local and back. \n\n\nupdate file/path status\n\n\nthere is some mess with \"approved.\" is it in session or in user.\n\n\nsplit web and rest servers.\n\n\n\n\nscaling\n\n\nuser friendliness\n\n\n\n\nadd buttons to terminate request\n\n\nadd visualizations to show progress (kibana visualization)\n\n\nadd icons to clone request -> just opens create web page and prepopulates with values from the original request.\n\n\nget user info in ES. currently most not stored.\n\n\n\n\nuser\n\n\n\n\nGET /profile - renders profile page. preloads users data from ES. will be simpler once ajax call gets data from /user\n\n\n\n\nGET /users - renders users page. ajax call gets data from /users_data.\n\n\n\n\n\n\nGET /authorize/:user_id\n\n\n\n\n\n\nGET /get_requests - returns requests data for a user. web called. should not be needed once page makes ajax call to /user/requests/\n\n\n\n\n\n\nGET /user/:user_id?  \nvalidated\n\n\nreturns json formated user profile data. if called from web interface and user is logged \nuser_id\n is not needed.\n\n\n\n\n\n\nGET /users_data  \nvalidated\n\n\nreturns json formated data on all users\n\n\n\n\n\n\nGET /user/requests/:user_id  \nvalidated\n\n\nreturns json formated info on all users requests\n\n\n\n\n\n\ndrequest\n\n\n\n\n\n\nGET /drequest/status/:status\n\n\nfor a given request status (eg. Defined) it finds the oldest request in that status. Returns all of that drequest data in json format. \n\n\n\n\n\n\nGET /drequest/:id \nvalidated\n\n\nfor a given request_id it returns all drequest data in json format. \n\n\n\n\n\n\nPUT /drequest/status/:id/:status/:info?\n\n\n\n\n\n\nPUT /drequest/terminate/:id \nvalidated\n\n\nSets status to Terminated for a given request_id and all the related paths.\n\n\n\n\n\n\nPUT /drequest/events_processed/:id/:events \nvalidated\n\n\nfor a given request_id increments number of events processed by \nevents\n. If all the events were processed, request status is set to \nDone\n.\n\n\n\n\n\n\nPOST /drequest/create \nvalidated\n\n\njson document must contain: userid, name, dataset, branches, events requested, optionaly: request description.\neg.\n{\n    \"userid\":\"a51dbd7e-d274-11e5-9b11-9be347a09ce0\",\n    \"name\": \"test x\",\n    \"dataset\": \"mc15_13TeV:mc15_13TeV.361106.PowhegPythia8EvtGen_AZNLOCTEQ6L1_Zee.merge.DAOD_STDM3.e3601_s2576_s2132_r6630_r6264_p2363_tid05630052_00\",\n    \"description\": \"just a test\",\n    \"columns\":[\"Electrons.pt()\",\"Electrons.eta()\",\"Electrons.phi()\"],\n    \"events\":123456\n}\n\n\n\n\n\n\nPOST /drequest/update \nvalidated\n\n\nupdates all the posted info.\n\n\n\n\n\n\nWEB only\n\n\n\n\nGET /wrequest_update/:rid \n\n\nGET /wrequest_prepare\n\n\nGET /wrequest_terminate\n\n\nGET /wrequest_manage\n\n\nPOST /wrequest_update\n\n\n\n\ndpath\n\n\n\n\n\n\nPOST /dpath/create \nvalidated\n\n\nto be used by DID-finder\n\n\n\n\n\n\nGET /dpath/transform/\n\n\nused by transformer. If there is a path that is in \nValidated\n state it is updated to \nTransforming\n and returned to the transformer.\n\n\n\n\n\n\nGET /dpath/transform/:rid/:status \nvalidated\n\n\nreturns data on a path belonging to \nrid\n request and in certain status.\n\n\n\n\n\n\nPUT /dpath/transform/:id/:status\n\n\ntransformer returns :id, status\n\n\n\n\n\n\nUnused for now\n\n\n\n\n\n\nGET /dpath/:id  \nvalidated\n\n\nreturns all the data about path\n\n\n\n\n\n\nGET /dpath/last_used/:rid\n\n\n\n\n\n\nRequests states and transitions\n\n\n\n\nAfter web or CLI request creation request is in \nCreated\n\n\nDID-finder will change it first to \nLookingUp\n and on finish to \nLookedUp\n or \nFailed\n\n\nValidator will change it to \nValidated\n or \nFailed\n\n\nFirst transformer will change state to \nProcessing\n or \nFailed\n\n\nLast transformer will change it to \nDelivered\n\n\nLast processed will change it to \nProcessed\n\n\n\n\nSingle file states and transitions\n\n\n\n\nDID-finder will create paths in state \nCreated\n\n\nValidator will change them to \nValidated\n\n\nTransformer will first move them to \nTransforming\n\n\nTransformer will change them to \nFailed\n or \nTransformed\n\n\n\n\ntransformer workflow:\n\n\n\n\ngets dpath to process (_id, rid, path, file_events)\n\n\ngets drequest connected to that dpath (columns, events_transformed, events_transforming, events_requested )\n\n\nif transformation needed \n\n\nupdate dpath status to \nTransforming\n\n\nupdate drequest events_transforming\nelse\n\n\nupdate dpath status to NotNeeded\n\n\n\n\n\n\nonce transformation done update dpath status to \nTransformed\n, update drequest events_tranformed, events_transforming, and if needed drequest status to \nTransformed\n.",
            "title": "Implementation reference"
        },
        {
            "location": "/Implementation_reference/#implementation-reference",
            "text": "",
            "title": "Implementation reference"
        },
        {
            "location": "/Implementation_reference/#api",
            "text": "TODO:",
            "title": "API"
        },
        {
            "location": "/Implementation_reference/#imediate",
            "text": "logic in request to make it DONE when events processed finished.  logic in request to stop transformers when events served > needed.  make request buttons on web site correctly behave   define getters and setters for drequest and dpath variables. functions to go from es to local and back.   update file/path status  there is some mess with \"approved.\" is it in session or in user.  split web and rest servers.",
            "title": "imediate"
        },
        {
            "location": "/Implementation_reference/#scaling",
            "text": "",
            "title": "scaling"
        },
        {
            "location": "/Implementation_reference/#user-friendliness",
            "text": "add buttons to terminate request  add visualizations to show progress (kibana visualization)  add icons to clone request -> just opens create web page and prepopulates with values from the original request.  get user info in ES. currently most not stored.",
            "title": "user friendliness"
        },
        {
            "location": "/Implementation_reference/#user",
            "text": "GET /profile - renders profile page. preloads users data from ES. will be simpler once ajax call gets data from /user   GET /users - renders users page. ajax call gets data from /users_data.    GET /authorize/:user_id    GET /get_requests - returns requests data for a user. web called. should not be needed once page makes ajax call to /user/requests/    GET /user/:user_id?   validated  returns json formated user profile data. if called from web interface and user is logged  user_id  is not needed.    GET /users_data   validated  returns json formated data on all users    GET /user/requests/:user_id   validated  returns json formated info on all users requests",
            "title": "user"
        },
        {
            "location": "/Implementation_reference/#drequest",
            "text": "GET /drequest/status/:status  for a given request status (eg. Defined) it finds the oldest request in that status. Returns all of that drequest data in json format.     GET /drequest/:id  validated  for a given request_id it returns all drequest data in json format.     PUT /drequest/status/:id/:status/:info?    PUT /drequest/terminate/:id  validated  Sets status to Terminated for a given request_id and all the related paths.    PUT /drequest/events_processed/:id/:events  validated  for a given request_id increments number of events processed by  events . If all the events were processed, request status is set to  Done .    POST /drequest/create  validated  json document must contain: userid, name, dataset, branches, events requested, optionaly: request description.\neg.\n{\n    \"userid\":\"a51dbd7e-d274-11e5-9b11-9be347a09ce0\",\n    \"name\": \"test x\",\n    \"dataset\": \"mc15_13TeV:mc15_13TeV.361106.PowhegPythia8EvtGen_AZNLOCTEQ6L1_Zee.merge.DAOD_STDM3.e3601_s2576_s2132_r6630_r6264_p2363_tid05630052_00\",\n    \"description\": \"just a test\",\n    \"columns\":[\"Electrons.pt()\",\"Electrons.eta()\",\"Electrons.phi()\"],\n    \"events\":123456\n}    POST /drequest/update  validated  updates all the posted info.",
            "title": "drequest"
        },
        {
            "location": "/Implementation_reference/#web-only",
            "text": "GET /wrequest_update/:rid   GET /wrequest_prepare  GET /wrequest_terminate  GET /wrequest_manage  POST /wrequest_update",
            "title": "WEB only"
        },
        {
            "location": "/Implementation_reference/#dpath",
            "text": "POST /dpath/create  validated  to be used by DID-finder    GET /dpath/transform/  used by transformer. If there is a path that is in  Validated  state it is updated to  Transforming  and returned to the transformer.    GET /dpath/transform/:rid/:status  validated  returns data on a path belonging to  rid  request and in certain status.    PUT /dpath/transform/:id/:status  transformer returns :id, status",
            "title": "dpath"
        },
        {
            "location": "/Implementation_reference/#unused-for-now",
            "text": "GET /dpath/:id   validated  returns all the data about path    GET /dpath/last_used/:rid",
            "title": "Unused for now"
        },
        {
            "location": "/Implementation_reference/#requests-states-and-transitions",
            "text": "After web or CLI request creation request is in  Created  DID-finder will change it first to  LookingUp  and on finish to  LookedUp  or  Failed  Validator will change it to  Validated  or  Failed  First transformer will change state to  Processing  or  Failed  Last transformer will change it to  Delivered  Last processed will change it to  Processed",
            "title": "Requests states and transitions"
        },
        {
            "location": "/Implementation_reference/#single-file-states-and-transitions",
            "text": "DID-finder will create paths in state  Created  Validator will change them to  Validated  Transformer will first move them to  Transforming  Transformer will change them to  Failed  or  Transformed   transformer workflow:   gets dpath to process (_id, rid, path, file_events)  gets drequest connected to that dpath (columns, events_transformed, events_transforming, events_requested )  if transformation needed   update dpath status to  Transforming  update drequest events_transforming\nelse  update dpath status to NotNeeded    once transformation done update dpath status to  Transformed , update drequest events_tranformed, events_transforming, and if needed drequest status to  Transformed .",
            "title": "Single file states and transitions"
        },
        {
            "location": "/Installation/",
            "text": "Installation\n\n\nAll the tools can be installed in different kubernetes clusters. Here instructions for each tool separately.\nSecrets are all known to Ilija Vukotic.\n\n\nFrontend (ATM both web and REST API)\n\n\nKubectl commands listed should be executed from subdirectory \nkube\n. \n\n\nlabel the node to be used for the frontend\n\n\nkubectl label nodes <node name> es=capable\n\n\nask Lincoln/Ilija/Judith to open ES firewall for that nodes IP. To get that IP look for external IP in output of :\n\n\nkubectl describe node <node name>\n\n\nin AWS Route53 change A record for \nservicex.slateci.net\n to that IP\n\n\ncreate namespace\n\n\nkubectl create -f namespace.yaml\n\n\ncreate secrets with site tls cert\n\n\nkubectl create secret -n servicex generic cert-secret --from-file=tls.key=secrets/https-certs/servicex.key.pem --from-file=tls.crt=secrets/https-certs/servicex.cert.crt\n\n\ncreate secret with configuration\n\n\nkubectl create secret -n servicex generic config --from-file=conf=../config/config.json\n\n\ncreate secret for Elasticsearch access\n\n\nkubectl create secret -n servicex generic es-secret --from-file=es_conf=secrets/elasticsearch/elasticsearch.json\n\n\ncreate secret for Globus authentication\n\n\nkubectl create secret -n servicex generic globus-secret --from-file=gconf=secrets/globus-conf/globus-config.json\n\n\ncreate service account\n\n\nkubectl create -f service_account.yaml\n\n\ndeploy service and ingress\n\n\nkubectl create -f service.yaml\n\n\ndeploy the frontend\n\n\nkubectl create -f frontend.yaml\n\n\ndid-finder, validator and transformer\n\n\nWhile all three tools can be on different clusters they all require servicex namespace and a secret needed to access ATLAS data:\n\n\nkubectl create secret -n servicex generic x509-secret --from-file=userkey=secrets/xcache.key.pem --from-file=usercert=secrets/xcache.crt.pem\n\n\ndeploy the did-finder\n\n\nkubectl create -f did-finder.yaml\n\n\ndeploy the validator\n\n\nkubectl create -f validator.yaml\n\n\ndeploy the transformer\n\n\nkubectl create -f did-finder.yaml\n\n\nredis\n\n\nShould be done from \nservicex.redis/kube/standalone\n.\n\n\ncreate redis namespace\n\n\nkubectl create ns redis\n\n\ncreate redis monitor (optional)\n\n\nkubectl create kafka_monitor.yaml\n\n\ncreate master configuration secret\n\n\nkubectl create secret -n redis generic redis-master-conf --from-file=conf=../config/redis.conf\n\n\ndeploy master. The default configuration requires a node with 200GB of RAM.\n\n\nkubectl create -f redis.yaml\n\n\nget master node IP. In AWS Route53 change A record for \nredis.slateci.net\n to that IP\n\n\ncreate slave configuration secret\n\n\nkubectl create secret -n redis generic redis-slave-conf --from-file=conf=../config/redis-slave.conf\n\n\ndeploy slave (optional)\n\n\nkubectl create -f redis-slave.yaml\n\n\nkafka",
            "title": "Installation"
        },
        {
            "location": "/Installation/#installation",
            "text": "All the tools can be installed in different kubernetes clusters. Here instructions for each tool separately.\nSecrets are all known to Ilija Vukotic.",
            "title": "Installation"
        },
        {
            "location": "/Installation/#frontend-atm-both-web-and-rest-api",
            "text": "Kubectl commands listed should be executed from subdirectory  kube .   label the node to be used for the frontend  kubectl label nodes <node name> es=capable  ask Lincoln/Ilija/Judith to open ES firewall for that nodes IP. To get that IP look for external IP in output of :  kubectl describe node <node name>  in AWS Route53 change A record for  servicex.slateci.net  to that IP  create namespace  kubectl create -f namespace.yaml  create secrets with site tls cert  kubectl create secret -n servicex generic cert-secret --from-file=tls.key=secrets/https-certs/servicex.key.pem --from-file=tls.crt=secrets/https-certs/servicex.cert.crt  create secret with configuration  kubectl create secret -n servicex generic config --from-file=conf=../config/config.json  create secret for Elasticsearch access  kubectl create secret -n servicex generic es-secret --from-file=es_conf=secrets/elasticsearch/elasticsearch.json  create secret for Globus authentication  kubectl create secret -n servicex generic globus-secret --from-file=gconf=secrets/globus-conf/globus-config.json  create service account  kubectl create -f service_account.yaml  deploy service and ingress  kubectl create -f service.yaml  deploy the frontend  kubectl create -f frontend.yaml",
            "title": "Frontend (ATM both web and REST API)"
        },
        {
            "location": "/Installation/#did-finder-validator-and-transformer",
            "text": "While all three tools can be on different clusters they all require servicex namespace and a secret needed to access ATLAS data:  kubectl create secret -n servicex generic x509-secret --from-file=userkey=secrets/xcache.key.pem --from-file=usercert=secrets/xcache.crt.pem  deploy the did-finder  kubectl create -f did-finder.yaml  deploy the validator  kubectl create -f validator.yaml  deploy the transformer  kubectl create -f did-finder.yaml",
            "title": "did-finder, validator and transformer"
        },
        {
            "location": "/Installation/#redis",
            "text": "Should be done from  servicex.redis/kube/standalone .  create redis namespace  kubectl create ns redis  create redis monitor (optional)  kubectl create kafka_monitor.yaml  create master configuration secret  kubectl create secret -n redis generic redis-master-conf --from-file=conf=../config/redis.conf  deploy master. The default configuration requires a node with 200GB of RAM.  kubectl create -f redis.yaml  get master node IP. In AWS Route53 change A record for  redis.slateci.net  to that IP  create slave configuration secret  kubectl create secret -n redis generic redis-slave-conf --from-file=conf=../config/redis-slave.conf  deploy slave (optional)  kubectl create -f redis-slave.yaml",
            "title": "redis"
        },
        {
            "location": "/Installation/#kafka",
            "text": "",
            "title": "kafka"
        }
    ]
}